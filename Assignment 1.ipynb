{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7c76ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\program files\\anaconda\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\program files\\anaconda\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=43c7a251f2b26ddc4e044f2a553fae74f0458d6904d1a859ff758773caaa6a5e\n",
      "  Stored in directory: c:\\users\\monod\\appdata\\local\\pip\\cache\\wheels\\73\\2b\\cb\\099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f909884a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in d:\\program files\\anaconda\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\program files\\anaconda\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in d:\\program files\\anaconda\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\program files\\anaconda\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in d:\\program files\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8fd2f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in d:\\program files\\anaconda\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\program files\\anaconda\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\program files\\anaconda\\lib\\site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\program files\\anaconda\\lib\\site-packages (from requests) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\program files\\anaconda\\lib\\site-packages (from requests) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "09a7322b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request failed with status code: 503\n",
      "Retryin\n",
      "Request failed with status code: 503\n",
      "Retryin\n",
      "Request failed with status code: 503\n",
      "Retryin\n",
      "Request failed with status code: 503\n",
      "Retryin\n",
      "Request failed with status code: 503\n",
      "Retryin\n",
      "Null\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "\n",
    "url = \"https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%2C283&ref=sr_pg_1\"\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36',\n",
    "    'Accept-Language': 'en-US, en;q=0.5'\n",
    "}\n",
    "\n",
    "def scrape_website(url, headers):\n",
    "    max_retries = 5\n",
    "    retry_delay = 2\n",
    "    \n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                print(\"OK\")\n",
    "                soup = BeautifulSoup(response.content, 'html.parser')\n",
    "               \n",
    "                return\n",
    "            else:\n",
    "                print(f\"Request failed with status code: {response.status_code}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error: {e}\")\n",
    "        \n",
    "        # Retry after delay\n",
    "        print(\"Retryin\")\n",
    "        time.sleep(retry_delay)\n",
    "    \n",
    "    print(\"Null\")\n",
    "\n",
    "# Call the function to start scraping\n",
    "scrape_website(url, headers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9801ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASSIGNMENT 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "51b401c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Product URL  \\\n",
      "0    https://www.amazon.in/POLESTAR-Vintage-Laptop-...   \n",
      "1    https://www.amazon.in/ADISA-BP005-Weight-Casua...   \n",
      "2    https://www.amazon.in/Safari-Laptop-Backpack-R...   \n",
      "3    https://www.amazon.in/Safari-Laptop-Backpack-C...   \n",
      "4    https://www.amazon.in/gp/bestsellers/luggage/2...   \n",
      "..                                                 ...   \n",
      "157  https://www.amazon.in/Wildcraft-Ltrs-orange-Ru...   \n",
      "158  https://www.amazon.in/Puma-Unisex-Adult-Backpa...   \n",
      "159  https://www.amazon.in/PUMA-Laptop-Backpack-CAS...   \n",
      "160  https://www.amazon.in/Skybags-Unisex-Black-Fab...   \n",
      "161  https://www.amazon.in/Genie-Clara-Backpack-Wom...   \n",
      "\n",
      "                                          Product Name  Product Price  Rating  \\\n",
      "0    POLESTAR Vintage 15.6 inch 32 LTR Casual Lapto...          549.0     3.9   \n",
      "1           ADISA Light Weight Laptop Backpack 32 Ltrs          499.0     4.0   \n",
      "2    Safari Quill Laptop Backpack 26 Ltrs Water Res...          899.0     4.0   \n",
      "3    Safari Tribe 35 Ltrs Large Laptop Backpack wit...         1099.0     3.8   \n",
      "4    Sfane Polyester 23cms Duffle/Shoulder/Gym Bag ...          387.0     4.3   \n",
      "..                                                 ...            ...     ...   \n",
      "157         Wildcraft 45 Ltrs Grey and Orange Rucksack         1739.0     4.3   \n",
      "158  Puma Unisex-Adult Core Backpack, Parisian Nigh...          911.0     5.0   \n",
      "159                           PUMA Laptop Backpack IND         1059.0     3.9   \n",
      "160    Skybags Unisex Black Gucci Fabric 10L Backpacks          392.0     3.9   \n",
      "161  Genie Clara Backpack for Women - 3 compartment...         1279.0     4.4   \n",
      "\n",
      "     Number of Reviews  \n",
      "0               8966.0  \n",
      "1               5968.0  \n",
      "2                682.0  \n",
      "3               1577.0  \n",
      "4               7480.0  \n",
      "..                 ...  \n",
      "157             9013.0  \n",
      "158                1.0  \n",
      "159               39.0  \n",
      "160              103.0  \n",
      "161              183.0  \n",
      "\n",
      "[162 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def scrape_product_details(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36',\n",
    "        'Accept-Language': 'en-US, en;q=0.5'\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    product_urls = []\n",
    "    product_names = []\n",
    "    product_prices = []\n",
    "    product_ratings = []\n",
    "    product_reviews = []\n",
    "    product_asin = []\n",
    "\n",
    "    #product_list = soup.find_all('div', {'class': 's-card-container s-overflow-hidden aok-relative puis-wide-grid-style puis-wide-grid-style-t1 puis-include-content-margin puis puis-'}) # tried a couple of times but I received Null Data\n",
    "    product_list = soup.find_all('div', {'data-component-type': 's-search-result'}) # took help from another source\n",
    "    for product in product_list:\n",
    "        url_elem = product.find('a', {'class': 'a-link-normal'})\n",
    "        url = 'https://www.amazon.in' + url_elem['href'] if url_elem else None\n",
    "        product_urls.append(url)\n",
    "        \n",
    "        name_elem = product.find('span', {'class': 'a-size-medium a-color-base a-text-normal'})\n",
    "        name = name_elem.text.strip() if name_elem else None\n",
    "        product_names.append(name)\n",
    "        \n",
    "        price_elem = product.find('span', {'class': 'a-price-whole'})\n",
    "        price = price_elem.text.replace(',', '') if price_elem else None\n",
    "        price = price.replace('M.R.P: ', '') if price else None\n",
    "        product_prices.append(float(price) if price else None)\n",
    "        \n",
    "        rating_elem = product.find('span', {'class': 'a-icon-alt'})\n",
    "        rating = rating_elem.text.split()[0] if rating_elem else None\n",
    "        product_ratings.append(float(rating) if rating else None)\n",
    "        \n",
    "        reviews_elem = product.find('span', {'class': 'a-size-base'})\n",
    "        reviews = reviews_elem.text.replace(',', '') if reviews_elem else None\n",
    "        reviews = re.sub(r'\\D', '', reviews) if reviews else None\n",
    "        product_reviews.append(int(reviews) if reviews else None)\n",
    "        \n",
    "\n",
    "    data = {\n",
    "        'Product URL': product_urls,\n",
    "        'Product Name': product_names,\n",
    "        'Product Price': product_prices,\n",
    "        'Rating': product_ratings,\n",
    "        'Number of Reviews': product_reviews,\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "def scrape_multiple_pages(base_url, num_pages):\n",
    "    all_data = []\n",
    "    for page in range(1, num_pages + 1):\n",
    "        url = base_url + f'&page={page}'\n",
    "        data = scrape_product_details(url)\n",
    "        all_data.append(data)\n",
    "    \n",
    "    result = pd.concat(all_data, ignore_index=True)\n",
    "    return result\n",
    "\n",
    "base_url = 'https://www.amazon.in/s?k=bags&crid=2M096C61O4MLT&qid=1653308124&sprefix=ba%2Caps%2C283&ref=sr_pg_1'\n",
    "num_pages = 30\n",
    "\n",
    "result = scrape_multiple_pages(base_url, num_pages)\n",
    "print(result)\n",
    "result.to_csv('Assignment 1.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a483c70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b1995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d6939b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
